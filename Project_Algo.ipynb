{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fSrHnzlOt4G"
      },
      "source": [
        "# Project 2 AMD-DSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HahpQlliDkz8"
      },
      "source": [
        "In this project the main purpose is to find frequent itemsets considering two algortihms studied during the course of **Algorithm for massive dataset**:\n",
        "\n",
        "\n",
        "*   A-priori\n",
        "*   Park-Chen-Yu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rytplvKIDHJp"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTZqgYcoO6jG"
      },
      "source": [
        "The dataset for the project is the MeDAL dataset\n",
        "https://www.kaggle.com/datasets/xhlulu/medal-emnlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIvfV4yoM-t9",
        "outputId": "a06f7fcc-6a53-454e-aaa3-6b84b37a1e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading medal-emnlp.zip to /content\n",
            "100% 6.81G/6.82G [00:57<00:00, 146MB/s]\n",
            "100% 6.82G/6.82G [00:57<00:00, 126MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download from kaggle\n",
        "import os\n",
        "# os.environ['KAGGLE_USERNAME'] = \"xxxxxx\"\n",
        "# os.environ['KAGGLE_KEY'] = \"xxxxxx\"\n",
        "\n",
        "!kaggle datasets download xhlulu/medal-emnlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwDHdsBIPfMX",
        "outputId": "017e0eac-e4f1-45f0-8b67-a1058aa9e0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  medal-emnlp.zip\n",
            "  inflating: data/full_data.csv      \n",
            "  inflating: data/pretrain_subset/test.csv  \n",
            "  inflating: data/pretrain_subset/train.csv  \n",
            "  inflating: data/pretrain_subset/valid.csv  \n"
          ]
        }
      ],
      "source": [
        "# unpack\n",
        "!unzip medal-emnlp.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV9kXCTkRIoe"
      },
      "outputs": [],
      "source": [
        "!mv data/pretrain_subset/* data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_2aZIQ8DLF1"
      },
      "source": [
        "Import libraries and install them if not already available in Google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRx6bG8XQCbz",
        "outputId": "74c23b21-3a50-40b8-f6e7-41205e4e09c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "import time\n",
        "\n",
        "import math\n",
        "\n",
        "# to remove stop words\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "rAh88id8XWWH",
        "outputId": "fbb5c60a-90be-48cb-f8b7-a678bf2ad4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79ee75f85a80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://50461e61fbc2:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# PYSPARK #\n",
        "# set up for google colab\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "# set up for local use\n",
        "#spark = SparkSession.builder.appName(\"test\").master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# to check that it works correctly it should give SparkSession in output\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive for outputs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eVTbl2pvk_T",
        "outputId": "11df6864-88cd-4ac7-aced-b96b2a5fe765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvTUlhfq9CT-"
      },
      "source": [
        "## Data import and dataset selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQAG-H0bCxQo"
      },
      "source": [
        "We create a sample dataset to tune the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "Zafq2gGDOpYn",
        "outputId": "ece2670f-2614-4ed4-a084-95db361b56e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9999, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ABSTRACT_ID                                               TEXT  LOCATION  \\\n",
              "0      2069316  we developed an animal model of chronic allerg...        89   \n",
              "1      6967959  pyogenic granulomas represent the aquisition o...        34   \n",
              "2      3492721  the l immunotype lipopolysaccharide lps of nei...        97   \n",
              "3      8388738  inotropic reserve identified by dobutamine or ...        47   \n",
              "4      6234238  pyridoxinedependent seizure is a rare autosoma...        57   \n",
              "5      3874752  a total of PA isolates were collected from GA ...        99   \n",
              "6     13253027  while diminished ovarian reserve dor predicts ...        43   \n",
              "7      8512090  we describe two cases of simple heterozygosity...       160   \n",
              "8      3967251  by means of EC and quantitative histomorphomet...         3   \n",
              "9      3262191  in the present study lithocholic acid lca meta...        57   \n",
              "\n",
              "                          LABEL  \n",
              "0  functional residual capacity  \n",
              "1            pyogenic granuloma  \n",
              "2        phosphorylethanolamine  \n",
              "3       stress echocardiography  \n",
              "4     severe mental retardation  \n",
              "5          metallobetalactamase  \n",
              "6         antral follicle count  \n",
              "7        thalassemia intermedia  \n",
              "8               electrochemical  \n",
              "9                  eye movement  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-558a0ba8-e6fb-4e20-9e63-685b6b4847b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABSTRACT_ID</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2069316</td>\n",
              "      <td>we developed an animal model of chronic allerg...</td>\n",
              "      <td>89</td>\n",
              "      <td>functional residual capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6967959</td>\n",
              "      <td>pyogenic granulomas represent the aquisition o...</td>\n",
              "      <td>34</td>\n",
              "      <td>pyogenic granuloma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3492721</td>\n",
              "      <td>the l immunotype lipopolysaccharide lps of nei...</td>\n",
              "      <td>97</td>\n",
              "      <td>phosphorylethanolamine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8388738</td>\n",
              "      <td>inotropic reserve identified by dobutamine or ...</td>\n",
              "      <td>47</td>\n",
              "      <td>stress echocardiography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6234238</td>\n",
              "      <td>pyridoxinedependent seizure is a rare autosoma...</td>\n",
              "      <td>57</td>\n",
              "      <td>severe mental retardation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3874752</td>\n",
              "      <td>a total of PA isolates were collected from GA ...</td>\n",
              "      <td>99</td>\n",
              "      <td>metallobetalactamase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13253027</td>\n",
              "      <td>while diminished ovarian reserve dor predicts ...</td>\n",
              "      <td>43</td>\n",
              "      <td>antral follicle count</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8512090</td>\n",
              "      <td>we describe two cases of simple heterozygosity...</td>\n",
              "      <td>160</td>\n",
              "      <td>thalassemia intermedia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3967251</td>\n",
              "      <td>by means of EC and quantitative histomorphomet...</td>\n",
              "      <td>3</td>\n",
              "      <td>electrochemical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3262191</td>\n",
              "      <td>in the present study lithocholic acid lca meta...</td>\n",
              "      <td>57</td>\n",
              "      <td>eye movement</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-558a0ba8-e6fb-4e20-9e63-685b6b4847b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-558a0ba8-e6fb-4e20-9e63-685b6b4847b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-558a0ba8-e6fb-4e20-9e63-685b6b4847b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fbb009d9-f988-4d6d-8742-9c74237bc211\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbb009d9-f988-4d6d-8742-9c74237bc211')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fbb009d9-f988-4d6d-8742-9c74237bc211 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# take just one sample part of 10000 rows to start the understand the project\n",
        "df = pd.read_csv('data/test.csv', nrows=9999)\n",
        "filenew = 'test_10000.csv' # name of output file\n",
        "df.to_csv(filenew,index=False) # write csv of sample file\n",
        "\n",
        "# reading the CSV file\n",
        "df = pd.read_csv('test_10000.csv')\n",
        "\n",
        "# displaying the contents of the CSV file\n",
        "print(df.shape)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO850mJ1hgAg"
      },
      "outputs": [],
      "source": [
        "# Data import with Spark tool\n",
        "sc = spark.sparkContext\n",
        "# sample dataset import\n",
        "sw_sample = sc.textFile('test_10000.csv',minPartitions=4)\n",
        "# full dataset import\n",
        "sw_full = sc.textFile('data/full_data.csv',minPartitions=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjfWtiQs9UQi"
      },
      "source": [
        "### Functions and pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPA5ReeNPAfH"
      },
      "source": [
        "The detector must consider as baskets the strings contained in the text column of the full-data.csv file in the dataset, using words as items.\n",
        "The dataset will be prepared to be used for MBA with the following functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlA5djwqXN-m"
      },
      "outputs": [],
      "source": [
        "## FUNCTIONS FOR PRE_PROCESSING##\n",
        "\n",
        "# function to get rid of stop word with a filter\n",
        "def isNotStopWord(x):\n",
        "    x = x.split(\" \") # split input string separated by space\n",
        "    s=[] #create empty string\n",
        "    for i in x:\n",
        "        if not i in stop_words:\n",
        "            s.append(i)\n",
        "    return \" \".join(s)\n",
        "\n",
        "# function to remove duplicates in a string\n",
        "def remove_duplicates(input):\n",
        "    input = input.split(\" \") # split string separating word by space\n",
        "    UniqW = Counter(input) # create a dictionary using the counter method\n",
        "    s = \" \".join(UniqW.keys()) # joins two adjacent elements in iterable way\n",
        "    return s\n",
        "\n",
        "# function to remove duplicates and stop words in a string\n",
        "def remove_dupAndStop(input):\n",
        "    input = input.split(\" \") # split string separating word by space\n",
        "    UniqW = Counter(input) # create a dictionary using the counter method\n",
        "    for key in list(UniqW):#.keys():\n",
        "      if key in stop_words:\n",
        "        del UniqW[key]\n",
        "        #UniqW.pop(key)\n",
        "    s = \" \".join(UniqW.keys()) # joins two adjacent elements in iterable way\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToszTkwt-Di7",
        "outputId": "d1b23fca-4ca5-4d96-f853-7d9eb6efbb0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using the sample dataset\n",
            "Type of input sample file is: <class 'pyspark.rdd.PipelinedRDD'>\n",
            "Dimension of sample file is: 87\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['healthy',\n",
              "  'skeletal',\n",
              "  'muscle',\n",
              "  'mass',\n",
              "  'essential',\n",
              "  'attenuating',\n",
              "  'complications',\n",
              "  'obesity',\n",
              "  'importantly',\n",
              "  'function',\n",
              "  'maintained',\n",
              "  'adequate',\n",
              "  'repair',\n",
              "  'following',\n",
              "  'overuse',\n",
              "  'injury',\n",
              "  'purpose',\n",
              "  't0',\n",
              "  'investigate',\n",
              "  'impact',\n",
              "  'dio',\n",
              "  'dio',\n",
              "  'functionality',\n",
              "  'satellite',\n",
              "  'cell',\n",
              "  'sc',\n",
              "  'population',\n",
              "  'male',\n",
              "  'cblj',\n",
              "  'mice',\n",
              "  'fed',\n",
              "  'standard',\n",
              "  'chow',\n",
              "  'highfat',\n",
              "  'diet',\n",
              "  'kcal',\n",
              "  'fat',\n",
              "  'weeks',\n",
              "  'muscles',\n",
              "  'subjected',\n",
              "  'ctx',\n",
              "  'displayed',\n",
              "  'att',\n",
              "  'regeneration',\n",
              "  'indicated',\n",
              "  'prolonged',\n",
              "  'necrosis',\n",
              "  'delayed',\n",
              "  'expression',\n",
              "  'myod',\n",
              "  'myogenin',\n",
              "  'elevated',\n",
              "  'collagen',\n",
              "  'content',\n",
              "  'persistent',\n",
              "  'embryonic',\n",
              "  'mhc',\n",
              "  'chain',\n",
              "  'significant',\n",
              "  'differences',\n",
              "  'observed',\n",
              "  'scs',\n",
              "  'activate',\n",
              "  'normally',\n",
              "  'respond',\n",
              "  'exogenous',\n",
              "  'hepatocyte',\n",
              "  'growth',\n",
              "  'factor',\n",
              "  'hgf',\n",
              "  'despite',\n",
              "  'similar',\n",
              "  'receptor',\n",
              "  'cmet',\n",
              "  'density',\n",
              "  'furthermore',\n",
              "  'release',\n",
              "  'crushed',\n",
              "  'significantly',\n",
              "  'less',\n",
              "  'demonstrates',\n",
              "  'deficits',\n",
              "  'present',\n",
              "  'impairments',\n",
              "  'result',\n",
              "  'altered',\n",
              "  'hgfcmet',\n",
              "  'signaling',\n",
              "  'contributors'],\n",
              " ['aspirin',\n",
              "  'widely',\n",
              "  'used',\n",
              "  'analgesic',\n",
              "  'antiinflammatory',\n",
              "  'drug',\n",
              "  'recently',\n",
              "  'elucidated',\n",
              "  'anticoaggregatory',\n",
              "  'effect',\n",
              "  'low',\n",
              "  'dose',\n",
              "  't0',\n",
              "  'carried',\n",
              "  'investigate',\n",
              "  'synthesis',\n",
              "  'derivatives',\n",
              "  'aromatic',\n",
              "  'compound',\n",
              "  'antioxidant',\n",
              "  'biological',\n",
              "  'mics',\n",
              "  'prepared',\n",
              "  'esterification',\n",
              "  'presence',\n",
              "  'cdi',\n",
              "  'activities',\n",
              "  'examined',\n",
              "  'using',\n",
              "  'ac',\n",
              "  'bt',\n",
              "  'antiplatelet',\n",
              "  'aggregation',\n",
              "  'result',\n",
              "  'sj',\n",
              "  'showed',\n",
              "  'strong',\n",
              "  'aoa',\n",
              "  'activity',\n",
              "  'among',\n",
              "  'four',\n",
              "  'compounds',\n",
              "  'collagen',\n",
              "  'adp',\n",
              "  'paf',\n",
              "  'method',\n",
              "  'exhibited',\n",
              "  'stronger',\n",
              "  'reaction',\n",
              "  'finding',\n",
              "  'demonstrates',\n",
              "  'useful',\n",
              "  'care',\n",
              "  'aging',\n",
              "  'olddisease',\n",
              "  'anticoagulant']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Dataset selection -> simplified one\n",
        "sw = sw_sample.sample(False, 0.01, 81)\n",
        "n_baskets = sw.count()\n",
        "print(\"You are using the sample dataset\")\n",
        "print(\"Type of input sample file is:\",type(sw))\n",
        "print(\"Dimension of sample file is:\",n_baskets)\n",
        "\n",
        "# Data preprocessing\n",
        "sw = sw.map(lambda x: x.split(',')[1]) #select only TEXT column\n",
        "firstRow = sw.first() # get first row of the headers\n",
        "sw= sw.filter(lambda x: x!=firstRow) #remove first row\n",
        "sw = sw.map(remove_duplicates) #remove duplicates\n",
        "sw = sw.map(isNotStopWord)#.map(lambda x:x) #remove stopword\n",
        "#sw = sw.map(remove_dupAndStop) #remove duplicates and stop words\n",
        "sw = sw.map(lambda word: word.lower()) # get lower case\n",
        "sw = sw.map(lambda x: x.split(\" \"))\n",
        "sw.take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTADgNz37Crb"
      },
      "source": [
        "## Step by Step into the implemented algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNWGeKXQ_VD6"
      },
      "source": [
        " ### A-priori\n",
        " Used to understand each step of the A-priori algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3If5M88FP_Q"
      },
      "source": [
        "To perform A-priori algorithm steps, few functions need to implementes to count singletons, pairs, triples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGKptWQY6Bq2"
      },
      "outputs": [],
      "source": [
        "## FUNCTIONS FOR A_PRIORI##\n",
        "\n",
        "# count occurances of singletons and sort them descending\n",
        "def count_freq_1(rdd):\n",
        "    return (rdd.flatMap(lambda word: word) # flat word\n",
        "            .map(lambda word: (word, 1)) #add 1\n",
        "            .reduceByKey(lambda a,b: a+b) #reduce and sum\n",
        "            .filter(lambda x: x[1] >= min_support) #above the min support\n",
        "            #.sortBy(lambda x: x[1],False) #sort descending\n",
        "           )\n",
        "\n",
        "# function to filter only word which are frequent items\n",
        "def isInFreqTable(x):\n",
        "    s=[] #create empty string\n",
        "    # check word in string that are frequent item\n",
        "    for i in x:\n",
        "        if i in pass1_out:\n",
        "            s.append(i)\n",
        "    return s\n",
        "\n",
        "# function to create frequent pairs\n",
        "def makePairs(x):\n",
        "    # create pairs of frequent singletons using nested loops\n",
        "    res = []\n",
        "    n = len(x)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            res.append((x[i], x[j]))\n",
        "    return res\n",
        "\n",
        "# count occurances of pairs\n",
        "def count_freq_2(rdd):\n",
        "    return (rdd.map(isInFreqTable)  #filter only frequent item\n",
        "            .map(makePairs) #create pairs of frequent items\n",
        "            .flatMap(lambda xs: [x[0:2] for x in xs])  #flatten pairs\n",
        "            .map(lambda word: (word, 1)) #add 1 to the pairs\n",
        "            .reduceByKey(lambda a,b: a+b) # reduce and sum\n",
        "            .filter(lambda x: x[1] >= min_support) #filter above threshold\n",
        "            #.sortBy(lambda x: x[1],False) #sort descending\n",
        "           )\n",
        "\n",
        "# function to filter only pairs which are frequent pairs\n",
        "def isInPairTable(x):\n",
        "    s=[] #create empty string\n",
        "    # # check words in string that are frequent pairs\n",
        "    for i in x:\n",
        "        if i in pass2_outFlat:\n",
        "            s.append(i)\n",
        "    return s\n",
        "\n",
        "# function to create frequent triples\n",
        "def makeTriple(x):\n",
        "  res = []\n",
        "  for combo in combinations(x, 3):  # 2 for pairs, 3 for triplets, etc\n",
        "    res.append((combo))\n",
        "  return res\n",
        "\n",
        "# function to count occurances of triples\n",
        "def count_freq_3(rdd):\n",
        "    return (rdd.map(isInPairTable)  #filter only frequent pairs\n",
        "            .map(makeTriple) #makeComb\n",
        "            .flatMap(lambda xs: [x[0:3] for x in xs])  #flatten triples\n",
        "            .map(lambda word: (word, 1)) #add 1 to triples\n",
        "            .reduceByKey(lambda a,b: a+b) #reduce and sum\n",
        "            .filter(lambda x: x[1] >= min_support) # above support threshold\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS1IObbAH4oW"
      },
      "source": [
        "The A-priori algorithm is developed as following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5tQ37LI_Cu5",
        "outputId": "9059b693-874c-4270-f73a-3446fb3d24eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of baskets considered in this project 87\n",
            "Min support considered is 5% of the total number of baskets\n",
            "Total value of the min support 4\n"
          ]
        }
      ],
      "source": [
        "#set up\n",
        "perc_min_supp = 0.05\n",
        "min_support = round(perc_min_supp*n_baskets) #filter the value of the\n",
        "print(\"Number of baskets considered in this project\",n_baskets)\n",
        "print(\"Min support considered is\",f\"{perc_min_supp:.0%}\", \"of the total number of baskets\")\n",
        "print(\"Total value of the min support\",min_support)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_clfZ1KxH-UI"
      },
      "source": [
        "1° pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwe2L0IWC2et",
        "outputId": "2efb9fa0-ff7b-4701-b754-dd15090ce9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent items:  340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('healthy', 5),\n",
              " ('sc', 5),\n",
              " ('chain', 4),\n",
              " ('significantly', 13),\n",
              " ('result', 4),\n",
              " ('used', 11),\n",
              " ('presence', 14),\n",
              " ('examined', 10),\n",
              " ('using', 17),\n",
              " ('showed', 15)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# count singletons occurance\n",
        "sw_single = count_freq_1(sw)\n",
        "print(\"number of frequent items: \",sw_single.count())\n",
        "sw_single.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-h7HP7JDPd7",
        "outputId": "1e23e84f-efb6-4d13-905a-1b3d554047b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['healthy',\n",
              " 'sc',\n",
              " 'chain',\n",
              " 'significantly',\n",
              " 'result',\n",
              " 'used',\n",
              " 'presence',\n",
              " 'examined',\n",
              " 'using',\n",
              " 'showed']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# create a list of frequent singletons\n",
        "pass1_out = sw_single.map(lambda x: x[0]).collect()\n",
        "pass1_out[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDj9Li5gIBx6"
      },
      "source": [
        "2° pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8Us-bYsC8Wz",
        "outputId": "1e0b56d1-9f2f-43db-c659-fceaee3bd5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent pairs 230\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('effect', 'presence'), 4),\n",
              " (('studies', 'demonstrated'), 4),\n",
              " (('patients', 'high'), 4),\n",
              " (('patients', 'performed'), 4),\n",
              " (('present', 'well'), 4),\n",
              " (('t3', 'suggest'), 6),\n",
              " (('group', 'groups'), 5),\n",
              " (('t0', 'protein'), 4),\n",
              " (('determine', 'whether'), 4),\n",
              " (('rats', 'significant'), 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# count pairs\n",
        "sw_pair = count_freq_2(sw)\n",
        "print(\"number of frequent pairs\",sw_pair.count())\n",
        "sw_pair.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zKqAIldEemG",
        "outputId": "2a74484f-928a-455d-f5f3-58c615e793c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('effect', 'presence'),\n",
              " ('studies', 'demonstrated'),\n",
              " ('patients', 'high'),\n",
              " ('patients', 'performed'),\n",
              " ('present', 'well'),\n",
              " ('t3', 'suggest'),\n",
              " ('group', 'groups'),\n",
              " ('t0', 'protein'),\n",
              " ('determine', 'whether'),\n",
              " ('rats', 'significant')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# create a list of frequent pairs\n",
        "pass2_out = sw_pair.map(lambda x: x[0]).collect()\n",
        "pass2_out[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EwaxTOOJteg",
        "outputId": "ec9ae714-db67-45ba-9949-17986deba271"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['effect', 'presence', 'studies', 'demonstrated', 'patients',\n",
              "       'high', 'patients', 'performed', 'present', 'well'], dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "pass2_outFlat = np.array(pass2_out).flatten() #flat the list of frequent pairs in which triples will check\n",
        "pass2_outFlat[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt2_MaQZIEsj"
      },
      "source": [
        "Further steps to find 3-size frequent items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsLO4B6UFDnu",
        "outputId": "80befbe5-84c0-4772-e536-127c6ea8cc06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent triples 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('determine', 'whether', 'could'), 4),\n",
              " (('effects', 'also', 'results'), 4),\n",
              " (('effects', 'mgkg', 'significant'), 4),\n",
              " (('also', 'cell', 'may'), 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# count triples\n",
        "sw_triples = count_freq_3(sw)\n",
        "print(\"number of frequent triples\",sw_triples.count())\n",
        "sw_triples.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4NVVG9GFHNB"
      },
      "outputs": [],
      "source": [
        "# create a list of frequent triples\n",
        "pass3_out = sw_triples.map(lambda x: x[0]).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Park, Chen, Yu"
      ],
      "metadata": {
        "id": "xIKeZw8piNko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define min support and number of buckets\n",
        "n_buckets = math.floor(n_baskets/4)\n",
        "perc_min_supp = 0.05\n",
        "min_support = round(perc_min_supp*n_baskets) #filter the value of the\n",
        "#min_support = 5\n",
        "print(\"Number of baskets considered in this project\",n_baskets)\n",
        "print(\"n_buckets for hashing:\", n_buckets)\n",
        "print(\"Min support considered is\",f\"{perc_min_supp:.0%}\", \"of the total number of baskets\")\n",
        "print(\"Total value of the min support\",min_support)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7njTjwSXiYuy",
        "outputId": "05bc703b-9100-40fd-ee7d-5ddb8c80e068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of baskets considered in this project 87\n",
            "n_buckets for hashing: 21\n",
            "Min support considered is 5% of the total number of baskets\n",
            "Total value of the min support 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1st pass"
      ],
      "metadata": {
        "id": "DGUa8mFvinzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.0 count items and find frequent one as A-priori\n",
        "freq1 = count_freq_1(sw)\n",
        "freq1_out = freq1.map(lambda x: x[0])\n",
        "print('number of frequent items',freq1.count())\n",
        "freq1.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UwfPPq3imK-",
        "outputId": "9cc493b4-34b4-4868-8e2a-b6ccf057111b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent items 340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('healthy', 5),\n",
              " ('sc', 5),\n",
              " ('chain', 4),\n",
              " ('significantly', 13),\n",
              " ('result', 4),\n",
              " ('used', 11),\n",
              " ('presence', 14),\n",
              " ('examined', 10),\n",
              " ('using', 17),\n",
              " ('showed', 15)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.a generate all pairs while examining each basket\n",
        "nn_comb = 2\n",
        "pairs = sw.map(lambda x: list(combinations(x,nn_comb))).flatMap(lambda x:x) # using itertool\n",
        "print(\"frequent pairs\",pairs.count())\n",
        "pairs.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTmghDL_ivDs",
        "outputId": "8db5b930-067b-4d93-f60b-9f405e2e4470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frequent pairs 313016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('healthy', 'skeletal'),\n",
              " ('healthy', 'muscle'),\n",
              " ('healthy', 'mass'),\n",
              " ('healthy', 'essential'),\n",
              " ('healthy', 'attenuating')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.b: count each pair in the baskets\n",
        "count_pairs =pairs.map(lambda word:(word,1)) # add 1 to each pair\n",
        "count_pairs = count_pairs.reduceByKey(lambda a,b:a+b).sortBy(lambda x: x[1],False) # sum the pair grouping them by item\n",
        "count_pairs.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNyG1Unzi9IO",
        "outputId": "1ca14cb1-1732-4d18-d7e2-2940dd2f9b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('also', 'results'), 8),\n",
              " (('effect', 'results'), 7),\n",
              " (('also', 'suggest'), 7),\n",
              " (('t3', 'suggest'), 6),\n",
              " (('evaluated', 'results'), 6),\n",
              " (('presence', 'low'), 6),\n",
              " (('present', 'showed'), 6),\n",
              " (('data', 'suggest'), 6),\n",
              " (('also', 'may'), 6),\n",
              " (('increased', 'due'), 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.c: before hashing pairs to buckets, attached an index\n",
        "comb_index=count_pairs.zipWithUniqueId().sortBy(lambda x: x[1],True)\n",
        "#comb_index=count_pairs.zipWithIndex() #in alternative\n",
        "comb_index.take(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfdC8gtXjJeZ",
        "outputId": "2efcc70b-bb85-4b1b-d050-5c384cfa06b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((('also', 'results'), 8), 0),\n",
              " ((('healthy', 'skeletal'), 1), 3),\n",
              " ((('effect', 'results'), 7), 4),\n",
              " ((('healthy', 'investigate'), 1), 7),\n",
              " ((('also', 'suggest'), 7), 8),\n",
              " ((('healthy', 'population'), 1), 11),\n",
              " ((('t3', 'suggest'), 6), 12),\n",
              " ((('healthy', 'fed'), 1), 15),\n",
              " ((('evaluated', 'results'), 6), 16),\n",
              " ((('healthy', 'fat'), 1), 19),\n",
              " ((('presence', 'low'), 6), 20),\n",
              " ((('healthy', 'displayed'), 1), 23),\n",
              " ((('present', 'showed'), 6), 24),\n",
              " ((('healthy', 'att'), 1), 27),\n",
              " ((('data', 'suggest'), 6), 28),\n",
              " ((('healthy', 'prolonged'), 1), 31),\n",
              " ((('also', 'may'), 6), 32),\n",
              " ((('healthy', 'delayed'), 1), 35),\n",
              " ((('increased', 'due'), 6), 36),\n",
              " ((('healthy', 'expression'), 1), 39)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.c: hashing pairs to buckets\n",
        "# organize data in triples - bucket_id, pairs, value\n",
        "pairs_buck = comb_index.map(lambda h:(h[1]%n_buckets,(h[0][0]), h[0][1]))\n",
        "pairs_buck.take(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6uSupYjUOk",
        "outputId": "77793771-ee3a-44c5-afb6-d78de5f5635f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, ('also', 'results'), 8),\n",
              " (3, ('healthy', 'skeletal'), 1),\n",
              " (4, ('effect', 'results'), 7),\n",
              " (7, ('healthy', 'investigate'), 1),\n",
              " (8, ('also', 'suggest'), 7),\n",
              " (11, ('healthy', 'population'), 1),\n",
              " (12, ('t3', 'suggest'), 6),\n",
              " (15, ('healthy', 'fed'), 1),\n",
              " (16, ('evaluated', 'results'), 6),\n",
              " (19, ('healthy', 'fat'), 1),\n",
              " (20, ('presence', 'low'), 6),\n",
              " (2, ('healthy', 'displayed'), 1),\n",
              " (3, ('present', 'showed'), 6),\n",
              " (6, ('healthy', 'att'), 1),\n",
              " (7, ('data', 'suggest'), 6),\n",
              " (10, ('healthy', 'prolonged'), 1),\n",
              " (11, ('also', 'may'), 6),\n",
              " (14, ('healthy', 'delayed'), 1),\n",
              " (15, ('increased', 'due'), 6),\n",
              " (18, ('healthy', 'expression'), 1),\n",
              " (19, ('also', 'cell'), 6),\n",
              " (1, ('healthy', 'collagen'), 1),\n",
              " (2, ('effects', 'results'), 6),\n",
              " (5, ('healthy', 'significant'), 1),\n",
              " (6, ('effects', 'suggest'), 6),\n",
              " (9, ('healthy', 'differences'), 1),\n",
              " (10, ('cell', 'may'), 6),\n",
              " (13, ('healthy', 'scs'), 1),\n",
              " (14, ('group', 'groups'), 5),\n",
              " (17, ('healthy', 'exogenous'), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.d keep only bucket_id, value and reduce\n",
        "buck_freq=pairs_buck.map(lambda t:(t[0],t[2])).reduceByKey(lambda a,b:a+b)\n",
        "# 1.e filter frequent buckets\n",
        "buckFreq = buck_freq.filter(lambda x:x[1]>=min_support).sortByKey()\n",
        "buckFreq.take(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvE587gEjeE5",
        "outputId": "cc50300f-b6fd-4500-e351-be5d1821b97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 14910),\n",
              " (1, 14904),\n",
              " (2, 14905),\n",
              " (3, 14906),\n",
              " (4, 14909),\n",
              " (5, 14904),\n",
              " (6, 14905),\n",
              " (7, 14906),\n",
              " (8, 14909),\n",
              " (9, 14903),\n",
              " (10, 14905),\n",
              " (11, 14906),\n",
              " (12, 14908),\n",
              " (13, 14902),\n",
              " (14, 14904),\n",
              " (15, 14906),\n",
              " (16, 14907),\n",
              " (17, 14902),\n",
              " (18, 14904),\n",
              " (19, 14906)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.f: get list of freq pairs\n",
        "freq_buck = buckFreq.map(lambda x: x[0]).collect()\n",
        "# 1.g: prepare as bitmap: 1 if in freq bucket table 0 otherwise\n",
        "bitmap = pairs_buck.map(lambda a:((a[1],a[2]),1 if a[0] in freq_buck else 0 )) #pair,counter of the pair,bucket\n",
        "bitmap.take(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EANUJz-ij6rr",
        "outputId": "8b65c95d-5a68-46ba-d009-d97e6a0f244c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((('also', 'results'), 8), 1),\n",
              " ((('healthy', 'skeletal'), 1), 1),\n",
              " ((('effect', 'results'), 7), 1),\n",
              " ((('healthy', 'investigate'), 1), 1),\n",
              " ((('also', 'suggest'), 7), 1),\n",
              " ((('healthy', 'population'), 1), 1),\n",
              " ((('t3', 'suggest'), 6), 1),\n",
              " ((('healthy', 'fed'), 1), 1),\n",
              " ((('evaluated', 'results'), 6), 1),\n",
              " ((('healthy', 'fat'), 1), 1),\n",
              " ((('presence', 'low'), 6), 1),\n",
              " ((('healthy', 'displayed'), 1), 1),\n",
              " ((('present', 'showed'), 6), 1),\n",
              " ((('healthy', 'att'), 1), 1),\n",
              " ((('data', 'suggest'), 6), 1),\n",
              " ((('healthy', 'prolonged'), 1), 1),\n",
              " ((('also', 'may'), 6), 1),\n",
              " ((('healthy', 'delayed'), 1), 1),\n",
              " ((('increased', 'due'), 6), 1),\n",
              " ((('healthy', 'expression'), 1), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.h: reorganize bitmap with bucket_id, pair, bit value\n",
        "bitmap = bitmap.map(lambda a:(a[0][0],(a[0][1]),a[1]))\n",
        "# 1.i: keep pairs and bitmap value = 1\n",
        "bit1= bitmap.map(lambda x:(x[0],(x[1],x[2])))\n",
        "bits_1 = bit1.filter(lambda x: (x[1][1] ==1)) # filter bit=1\n",
        "bits_1.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPfXuhXVkUVR",
        "outputId": "97915f2e-4ebb-43e2-dc11-43208ef5c3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('also', 'results'), (8, 1)),\n",
              " (('healthy', 'skeletal'), (1, 1)),\n",
              " (('effect', 'results'), (7, 1)),\n",
              " (('healthy', 'investigate'), (1, 1)),\n",
              " (('also', 'suggest'), (7, 1)),\n",
              " (('healthy', 'population'), (1, 1)),\n",
              " (('t3', 'suggest'), (6, 1)),\n",
              " (('healthy', 'fed'), (1, 1)),\n",
              " (('evaluated', 'results'), (6, 1)),\n",
              " (('healthy', 'fat'), (1, 1))]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2nd pass"
      ],
      "metadata": {
        "id": "mYyNf0miktUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makePairs2(x):\n",
        "    # function to create pairs of frequent singletons\n",
        "    # using nested loops with all possible order\n",
        "    res = []\n",
        "    n = len(x)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            res.append((x[i], x[j]))\n",
        "            res.append((x[j], x[i]))\n",
        "    return res"
      ],
      "metadata": {
        "id": "2zL799Jikvde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.0: take frequent items and make pairs\n",
        "tt = makePairs2(freq1_out.collect())\n",
        "# it is a list that need to be transformed into rdd\n",
        "rdd1 = sc.parallelize(tt)\n",
        "rdd1 = rdd1.map(lambda x: ((x[0],x[1]),1))\n",
        "print(\"Number of pairs generated with freq.items:\", rdd1.count())\n",
        "rdd1.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zlQwVJWk03l",
        "outputId": "14c5aaa6-8d8b-49f2-fe35-fa05875e83af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pairs generated with freq.items: 115260\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('healthy', 'sc'), 1), (('sc', 'healthy'), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.a: link the possible frequent pairs to bitmap with 1 in bit\n",
        "freq2_bitmap = rdd1.join(bits_1) #join pairs (a,b) with their bucket_id and counter\n",
        "freq2_bitmap.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toTGTWNllUv7",
        "outputId": "15c22f86-3c86-4b54-f62f-7bf404b9bbea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('healthy', 'presence'), (1, (1, 1))),\n",
              " (('healthy', 'risk'), (1, (1, 1))),\n",
              " (('healthy', 'years'), (1, (1, 1))),\n",
              " (('healthy', 'identify'), (1, (1, 1))),\n",
              " (('healthy', 'mg'), (1, (1, 1))),\n",
              " (('assess', 'healthy'), (1, (1, 1))),\n",
              " (('healthy', 'two'), (1, (1, 1))),\n",
              " (('oral', 'healthy'), (1, (1, 1))),\n",
              " (('healthy', 'mice'), (1, (1, 1))),\n",
              " (('healthy', 'determine'), (1, (1, 1)))]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.b: reorganize freq2 rdd keeping pairs and count\n",
        "freq2_bitmap = freq2_bitmap.map(lambda x:(x[0],x[1][1][0]))\n",
        "freq2_bitmap = freq2_bitmap.filter(lambda x: (x[1] >= min_support))\n",
        "freq2_bitmap.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsctaMdCldSl",
        "outputId": "729e9cea-c50c-4fc2-a919-3f34ce66b12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('rats', 'significantly'), 4),\n",
              " (('significantly', 'compared'), 4),\n",
              " (('c2', 'significantly'), 4),\n",
              " (('significantly', 'increased'), 4),\n",
              " (('level', 'significantly'), 5),\n",
              " (('presence', 'showed'), 4),\n",
              " (('presence', 'low'), 6),\n",
              " (('using', 'caused'), 4),\n",
              " (('t0', 'using'), 4),\n",
              " (('t0', 'showed'), 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.c: get frequent itemsets\n",
        "freq_2 = freq2_bitmap.map(lambda x : x[0])\n",
        "print(\"number of frequent pairs\", freq_2.count())\n",
        "freq_2.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C24MacXrluXF",
        "outputId": "78e92ccb-a6d0-4496-f1c0-8958c612237f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent pairs 230\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rats', 'significantly'),\n",
              " ('significantly', 'compared'),\n",
              " ('c2', 'significantly'),\n",
              " ('significantly', 'increased'),\n",
              " ('level', 'significantly')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the whole sample dataset\n",
        "with the full sample dataset of 10000 baskets"
      ],
      "metadata": {
        "id": "g1UvzL8gI77f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw = sw_sample\n",
        "n_baskets = sw.count()\n",
        "print(\"You are using the sample dataset\")\n",
        "print(\"Type of input sample file is:\",type(sw))\n",
        "print(\"Dimension of full dataset is:\",n_baskets)\n",
        "\n",
        "# Data preprocessing\n",
        "sw = sw.map(lambda x: x.split(',')[1]) #select only TEXT column\n",
        "firstRow = sw.first() # get first row of the headers\n",
        "sw= sw.filter(lambda x: x!=firstRow) #remove first row\n",
        "sw = sw.map(remove_duplicates) #remove duplicates\n",
        "sw = sw.map(isNotStopWord)#.map(lambda x:x) #remove stopword\n",
        "sw = sw.map(lambda word: word.lower()) # get lower case\n",
        "sw = sw.map(lambda x: x.split(\" \"))\n"
      ],
      "metadata": {
        "id": "8QI4PMz1JXBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc734e19-98b9-4632-afdd-7ebe418d00b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using the sample dataset\n",
            "Type of input sample file is: <class 'pyspark.rdd.RDD'>\n",
            "Dimension of full dataset is: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A-priori"
      ],
      "metadata": {
        "id": "YWvVR4pUFoi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up\n",
        "perc_min_supp = 0.02\n",
        "min_support = round(perc_min_supp*n_baskets) #filter the value of the\n",
        "print(\"Number of baskets considered in this project\",n_baskets)\n",
        "print(\"Min support considered is\",f\"{perc_min_supp:.0%}\", \"of the total number of baskets\")\n",
        "print(\"Total value of the min support\",min_support)\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count singletons occurance\n",
        "sw_single = count_freq_1(sw)\n",
        "# create a list of frequent singletons\n",
        "#if sw_single.isEmpty()==True: print(\"No frequent singletons\")\n",
        "pass1_out = sw_single.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent singletons collected --> DONE\")\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter1 =intTime-startTime\n",
        "print(\"-> Intermediate time to calculate frequent singletons: \", t_inter1)\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count pairs\n",
        "sw_pair = count_freq_2(sw)\n",
        "#if sw_pair.isEmpty()==True: print(\"No frequent pairs\")\n",
        "# create a list of frequent pairs\n",
        "pass2_out = sw_pair.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent pairs collected --> DONE\")\n",
        "pass2_outFlat = np.array(pass2_out).flatten() #flat the list\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter2 =intTime-startTime\n",
        "print(\"-> Intermediate time to calculate frequent pairs: \", t_inter2)\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count triples\n",
        "sw_triples = count_freq_3(sw)\n",
        "#if sw_triples.isEmpty()==True: print(\"No frequent triples\")\n",
        "# create a list of frequent triples\n",
        "pass3_out = sw_triples.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent triples collected --> DONE\")\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter3 =intTime-startTime\n",
        "t_Apriori = t_inter1+ t_inter2 + t_inter3\n",
        "\n",
        "# Print results and time of calculation\n",
        "print(\"\\n\")\n",
        "print(\"-> Intermediate time to calculate frequent triples: \", t_inter3)\n",
        "print(\"-> Total Duration: \", t_Apriori)\n",
        "print(\"\\n\")\n",
        "print(\"Number of frequent singletons\", len(pass1_out))\n",
        "print(\"Number of frequent pairs\", len(pass2_out))\n",
        "print(\"Number of frequent triples\", len(pass3_out))\n",
        "print(\"Total Duration: \", t_Apriori)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihq-RHHjFuFw",
        "outputId": "76b41533-82bd-4078-8f8e-0696240b8f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of baskets considered in this project 10000\n",
            "Min support considered is 2% of the total number of baskets\n",
            "Total value of the min support 200\n",
            "--> Frequent singletons collected --> DONE\n",
            "-> Intermediate time to calculate frequent singletons:  3.2787694931030273\n",
            "--> Frequent pairs collected --> DONE\n",
            "-> Intermediate time to calculate frequent pairs:  36.83454346656799\n",
            "--> Frequent triples collected --> DONE\n",
            "\n",
            "\n",
            "-> Intermediate time to calculate frequent triples:  40.39197635650635\n",
            "-> Total Duration:  80.50528931617737\n",
            "\n",
            "\n",
            "Number of frequent singletons 729\n",
            "Number of frequent pairs 443\n",
            "Number of frequent triples 0\n",
            "Total Duration:  80.50528931617737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save freq_single into the output data folder\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori10000-1_output.txt', 'w')  as file:\n",
        "    for i in pass1_out :\n",
        "        file.write(str(i)+\"\\n\")\n",
        "\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori10000-2_output.txt', 'w')  as file:\n",
        "    for i in pass1_out :\n",
        "        file.write(str(i)+\"\\n\")\n",
        "\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori10000-3_output.txt', 'w')  as file:\n",
        "    for i in pass1_out :\n",
        "        file.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "GGA7Dy1IG-BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCY"
      ],
      "metadata": {
        "id": "6FI04BLTHYiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform PCY we would a forcing to limit amount of words in each text, otherwise in the first pass we would run into a lot of useless combinations. This fact was visible from step -by step tasks, but here below also some clarifications."
      ],
      "metadata": {
        "id": "3l9EJCr_2HSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_words = 85 #n.of words in each string of text\n",
        "n_buck = math.floor(n_baskets/4) #number of buckets\n",
        "perc_min_supp = 0.02\n",
        "min_support = round(perc_min_supp*n_baskets)\n",
        "#number of possible pairs\n",
        "poss_pairs = n_baskets*(n_words*(n_words-1)/2)\n",
        "#avg count of each bucket\n",
        "avg_buck_count= (n_baskets*n_words**2)/(2*n_buck)\n",
        "print('avg count of each bucket',avg_buck_count)\n",
        "s_exp = (n_baskets*n_words**2)/(2*min_support )\n",
        "print('Number of buckets expected:',s_exp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R-9UY5S_1hF",
        "outputId": "033fa6a2-7711-4fc5-87c8-1e4c9a28108a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg count of each bucket 14450.0\n",
            "Number of buckets expected: 180625.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make same changes to see a case in which we would benefit to have frequent buckets"
      ],
      "metadata": {
        "id": "KTJfBqWMBFUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_words = 5 #n.of words in each string of text\n",
        "n_buck = math.floor(n_baskets/4) #number of buckets\n",
        "perc_min_supp = 0.0025\n",
        "min_support = round(perc_min_supp*n_baskets)\n",
        "#number of possible pairs\n",
        "poss_pairs = n_baskets*(n_words*(n_words-1)/2)\n",
        "#avg count of each bucket\n",
        "avg_buck_count= (n_baskets*n_words**2)/(2*n_buck)\n",
        "print('avg count of each bucket',avg_buck_count)\n",
        "s_exp = (n_baskets*n_words**2)/(2*min_support )\n",
        "print('Number of buckets expected:',s_exp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RZo49BYBDbD",
        "outputId": "29d8411b-8ae5-4066-b843-27bffd895dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg count of each bucket 50.0\n",
            "Number of buckets expected: 5000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# important adjustment to limit word in strings of text\n",
        "sw = sw.map(lambda x: x[0:5])\n",
        "\n",
        "#define min support and number of buckets\n",
        "n_buckets = math.floor(n_baskets/4)\n",
        "#perc_min_supp = 0.02\n",
        "perc_min_supp = 0.0025\n",
        "min_support = round(perc_min_supp*n_baskets) #filter the value of the\n",
        "#min_support = 5\n",
        "print(\"Number of baskets considered in this project\",n_baskets)\n",
        "print(\"n_buckets for hashing:\", n_buckets)\n",
        "print(\"Min support considered is\",f\"{perc_min_supp:.0%}\", \"of the total number of baskets\")\n",
        "print(\"Total value of the min support\",min_support)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIxstYC43JZH",
        "outputId": "4013dbe1-e44d-4de7-c254-1d6b3fc4a9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of baskets considered in this project 10000\n",
            "n_buckets for hashing: 2500\n",
            "Min support considered is 0% of the total number of baskets\n",
            "Total value of the min support 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### 1st PASS ####\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count items and find frequent one as A-priori\n",
        "freq1 = count_freq_1(sw)\n",
        "freq1_out = freq1.map(lambda x: x[0])\n",
        "\n",
        "#freq1.take(10)\n",
        "\n",
        "# generate all pairs of the baskets\n",
        "nn_comb = 2\n",
        "pairs = sw.map(lambda x: list(combinations(x,nn_comb))).flatMap(lambda x:x) # using itertool\n",
        "\n",
        "# 1.b: count each pair in the baskets\n",
        "count_pairs =pairs.map(lambda word:(word,1)) # add 1 to each pair\n",
        "count_pairs = count_pairs.reduceByKey(lambda a,b:a+b).sortBy(lambda x: x[1],False) # sum the pair grouping them by item\n",
        "\n",
        "# 1.c: before hashing pairs to buckets, attached an index\n",
        "comb_hash=count_pairs.zipWithUniqueId()#.sortBy(lambda x: x[1],True)\n",
        "#comb_hash=count_pairs.zipWithIndex()\n",
        "\n",
        "# 1.d: hashing pairs to buckets\n",
        "pairs_buck = comb_hash.map(lambda h:(h[1]%n_buckets,(h[0][0]), h[0][1]))\n",
        "buck_freq=pairs_buck.map(lambda t:(t[0],t[2])).reduceByKey(lambda a,b:a+b) #organize data in triples - bucket_id, pairs, value\n",
        "# 1.e: check frequent buckets\n",
        "buckFreq = buck_freq.filter(lambda x:x[1]>=min_support).sortByKey()\n",
        "\n",
        "\n",
        "# 1.f: get list of freq pairs\n",
        "freq_buck = buckFreq.map(lambda x: x[0]).collect()\n",
        "# 1.g-h: if in freq bucket table 0 otherwise\n",
        "bitmap = pairs_buck.map(lambda a:((a[1],a[2]),1 if a[0] in freq_buck else 0 )) #pair,counter of the pair,bucket\n",
        "bitmap = bitmap.map(lambda a:(a[0][0],(a[0][1]),a[1]))\n",
        "\n",
        "\n",
        "# 1.h: keep pairs and bitmap value\n",
        "bit1= bitmap.map(lambda x:(x[0],(x[1],x[2])))\n",
        "bits_1 = bit1.filter(lambda x: (x[1][1] ==1)) # filter bit=1\n",
        "\n",
        "\n",
        "intTime = time.time()\n",
        "t_PCY1 =intTime-startTime\n",
        "print(\"-> Intermediate time of 1st pass: \", t_PCY1)\n",
        "print(\"\\n\")\n",
        "print('Number of frequent items:',freq1.count())\n",
        "print(\"Genarated pairs:\",pairs.count())\n",
        "print(\"Number of frequent buckets:\", buckFreq.count())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VDfx6qCHqmy",
        "outputId": "2c16ce02-9795-4772-dffa-ec2de8807dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Intermediate time of 1st pass:  7.88161039352417\n",
            "\n",
            "\n",
            "Number of frequent items: 275\n",
            "Genarated pairs: 99986\n",
            "Number of frequent buckets: 782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### 2nd PASS ####\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# 2.0: take frequent items and make pairs\n",
        "tt = makePairs2(freq1_out.collect())\n",
        "rdd1 = sc.parallelize(tt)\n",
        "rdd1 = rdd1.map(lambda x: ((x[0],x[1]),1))\n",
        "\n",
        "# 2.a: link the possible frequent pairs to bitmap of pair with 1\n",
        "freq2_bitmap = rdd1.join(bits_1) #join pairs (a,b) with their bucket_id and counter\n",
        "freq2_bitmap = freq2_bitmap.map(lambda x:(x[0],x[1][1][0]))\n",
        "#freq2 = freq2_bitmap\n",
        "freq2 = freq2_bitmap.filter(lambda x: (x[1] >= min_support))\n",
        "\n",
        "# 2.b get frequent itemsets\n",
        "freq2_out = freq2.map(lambda x : x[0])\n",
        "\n",
        "intTime = time.time()\n",
        "t_PCY2 =intTime-startTime\n",
        "t_pcy = t_PCY1+t_PCY2\n",
        "\n",
        "# Print results and time of calculation\n",
        "print(\"\\n\")\n",
        "print(\"-> Intermediate time of 2nd pass: \", t_PCY2)\n",
        "print(\"-> Total Duration: \", t_pcy)\n",
        "print(\"\\n\")\n",
        "print(\"Number of frequent pairs\", freq2.count())\n",
        "# print(\"Number of frequent pairs\", len(freq_2pcy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShxYehB34vz6",
        "outputId": "c2ac9117-96a8-413c-af2e-c664be169e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "-> Intermediate time of 2nd pass:  0.7181837558746338\n",
            "-> Total Duration:  8.599794149398804\n",
            "\n",
            "\n",
            "Number of frequent pairs 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save freq_pairs into the output data folder\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_PCY10000-1_output.txt', 'w')  as file:\n",
        "    for i in freq1.sortBy(lambda x: x[1],False).collect():\n",
        "        file.write(str(i)+\"\\n\")\n",
        "\n",
        "# save freq_pairs into the output data folder\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_PCY10000-2_output.txt', 'w')  as file:\n",
        "    for i in freq2.sortBy(lambda x: x[1],False).collect():\n",
        "        file.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "ufple9-XKBH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A-Priori on same sample dataset modified for PCY"
      ],
      "metadata": {
        "id": "Ygm-Xc2l9SNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count singletons occurance\n",
        "sw_single = count_freq_1(sw)\n",
        "# create a list of frequent singletons\n",
        "#if sw_single.isEmpty()==True: print(\"No frequent singletons\")\n",
        "pass1_out = sw_single.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent singletons collected --> DONE\")\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter1 =intTime-startTime\n",
        "print(\"-> Intermediate time to calculate frequent singletons: \", t_inter1)\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count pairs\n",
        "sw_pair = count_freq_2(sw)\n",
        "#if sw_pair.isEmpty()==True: print(\"No frequent pairs\")\n",
        "# create a list of frequent pairs\n",
        "pass2_out = sw_pair.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent pairs collected --> DONE\")\n",
        "pass2_outFlat = np.array(pass2_out).flatten() #flat the list\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter2 =intTime-startTime\n",
        "print(\"-> Intermediate time to calculate frequent pairs: \", t_inter2)\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count triples\n",
        "sw_triples = count_freq_3(sw)\n",
        "#if sw_triples.isEmpty()==True: print(\"No frequent triples\")\n",
        "# create a list of frequent triples\n",
        "pass3_out = sw_triples.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent triples collected --> DONE\")\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter3 =intTime-startTime\n",
        "t_Apriori = t_inter1+ t_inter2 + t_inter3\n",
        "\n",
        "# Print results and time of calculation\n",
        "print(\"\\n\")\n",
        "print(\"-> Intermediate time to calculate frequent triples: \", t_inter3)\n",
        "print(\"-> Total Duration: \", t_Apriori)\n",
        "print(\"\\n\")\n",
        "print(\"Number of frequent singletons\", len(pass1_out))\n",
        "print(\"Number of frequent pairs\", len(pass2_out))\n",
        "print(\"Number of frequent triples\", len(pass3_out))\n",
        "print(\"Total Duration: \", t_Apriori)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThIn_cbH9QnH",
        "outputId": "2525fa5a-2270-4288-b26a-ed4691313fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Frequent singletons collected --> DONE\n",
            "-> Intermediate time to calculate frequent singletons:  2.1801981925964355\n",
            "--> Frequent pairs collected --> DONE\n",
            "-> Intermediate time to calculate frequent pairs:  2.223590612411499\n",
            "--> Frequent triples collected --> DONE\n",
            "\n",
            "\n",
            "-> Intermediate time to calculate frequent triples:  2.2293832302093506\n",
            "-> Total Duration:  6.633172035217285\n",
            "\n",
            "\n",
            "Number of frequent singletons 275\n",
            "Number of frequent pairs 17\n",
            "Number of frequent triples 0\n",
            "Total Duration:  6.633172035217285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save freq_single into the output data folder\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori10000-1mod_output.txt', 'w')  as file:\n",
        "    for i in sw_single.sortBy(lambda x: x[1],False).collect() :\n",
        "        file.write(str(i)+\"\\n\")\n",
        "\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori10000-2mod_output.txt', 'w')  as file:\n",
        "    for i in sw_pair.sortBy(lambda x: x[1],False).collect() :\n",
        "        file.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "A7G5Iu5o-Wo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dshsnmE-SLd"
      },
      "source": [
        "## Main execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGRmgVhSIm4F"
      },
      "source": [
        "Use the full-data.csv file to evaluate results on the full dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPcj12iv-2Ni",
        "outputId": "c99e8d01-6e2e-4b7c-aaf9-34134264f727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using the full dataset\n",
            "Type of input sample file is: <class 'pyspark.rdd.RDD'>\n",
            "Dimension of full dataset is: 14393620\n"
          ]
        }
      ],
      "source": [
        "sw = sw_full\n",
        "n_baskets = sw.count()\n",
        "print(\"You are using the full dataset\")\n",
        "print(\"Type of input sample file is:\",type(sw))\n",
        "print(\"Dimension of full dataset is:\",n_baskets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0gAsahKJdSR"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "sw = sw.map(lambda x: x.split(',')[0]) #select only TEXT column\n",
        "firstRow = sw.first() # get first row of the headers\n",
        "sw= sw.filter(lambda x: x!=firstRow) #remove first row\n",
        "sw = sw.map(remove_duplicates) #remove duplicates\n",
        "sw = sw.map(isNotStopWord)#.map(lambda x:x) #remove stopword\n",
        "#sw = sw.map(remove_dupAndStop) #remove duplicates and stop words\n",
        "sw = sw.map(lambda word: word.lower()) # get lower case\n",
        "sw = sw.map(lambda x: x.split(\" \"))\n",
        "#sw.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw.first()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24jqtQLKsAWN",
        "outputId": "aa0cfca2-d9b8-4032-e9e6-6f3c92039805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alphabisabolol',\n",
              " 'primary',\n",
              " 'antipeptic',\n",
              " 'action',\n",
              " 'depending',\n",
              " 'dosage',\n",
              " 'caused',\n",
              " 'alteration',\n",
              " 'phvalue',\n",
              " 'proteolytic',\n",
              " 'activity',\n",
              " 'pepsin',\n",
              " 'reduced',\n",
              " 'percent',\n",
              " 'addition',\n",
              " 'bisabolol',\n",
              " 'ratio',\n",
              " 'occurs',\n",
              " 'case',\n",
              " 'direct',\n",
              " 'contact',\n",
              " 'previous',\n",
              " 'atp',\n",
              " 'inhibiting',\n",
              " 'effect',\n",
              " 'lost']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJXAwKXdIvEj"
      },
      "source": [
        "### A-priori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GopRUbChew-2"
      },
      "source": [
        "Run full dataset with the developed A-priori algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set up\n",
        "perc_min_supp = 0.02\n",
        "min_support = round(perc_min_supp*n_baskets) #filter the value of the\n",
        "print(\"Number of baskets considered in this project\",n_baskets)\n",
        "print(\"Min support considered is\",f\"{perc_min_supp:.0%}\", \"of the total number of baskets\")\n",
        "print(\"Total value of the min support\",min_support)\n",
        "\n",
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count singletons occurance\n",
        "sw_single = count_freq_1(sw)\n",
        "# create a list of frequent singletons\n",
        "#if sw_single.isEmpty()==True: print(\"No frequent singletons\")\n",
        "pass1_out = sw_single.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent singletons collected --> DONE\")\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter1 =intTime-startTime\n",
        "print(\"-> Intermediate time to calculate frequent singletons: \", t_inter1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TgfZT5poePo",
        "outputId": "ca82c646-aa34-4cd6-df50-55084abbc35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of baskets considered in this project 14393620\n",
            "Min support considered is 2% of the total number of baskets\n",
            "Total value of the min support 287872\n",
            "--> Frequent singletons collected --> DONE\n",
            "-> Intermediate time to calculate frequent singletons:  3003.829658508301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJEh7Xd4unJR"
      },
      "source": [
        "Set a connection to google drive to export frequent itemset that we computed thanks to the algorithms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save freq_single into the output data folder\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori1_output.txt', 'w')  as file:\n",
        "    for i in pass1_out :\n",
        "        file.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "ilmd4ml0vPYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count pairs\n",
        "sw_pair = count_freq_2(sw)\n",
        "#if sw_pair.isEmpty()==True: print(\"No frequent pairs\")\n",
        "# create a list of frequent pairs\n",
        "pass2_out = sw_pair.map(lambda x: x[0]).collect()\n",
        "print(\"--> Frequent pairs collected --> DONE\")\n",
        "pass2_outFlat = np.array(pass2_out).flatten() #flat the list\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter2 =intTime-startTime\n",
        "print(\"-> Intermediate time to calculate frequent pairs: \", t_inter2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHDZtM3CouFU",
        "outputId": "9f3d3dd8-f1d0-49cd-8809-1361b1dced6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Frequent pairs collected --> DONE\n",
            "-> Intermediate time to calculate frequent pairs:  25835.283787488937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save freq_pairs into the output data folder\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori2_output.txt', 'w')  as file:\n",
        "    for i in pass2_out:\n",
        "        file.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "uWYTJPn2vWpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to be used to import back data after reconnection\n",
        "from ast import literal_eval as make_tuple\n",
        "\n",
        "# reassign pass1_out\n",
        "p_list=[]\n",
        "a=open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori1_output.txt',\"r\").readlines()\n",
        "for i in a:\n",
        "    if i!=\"\":\n",
        "        p_list.append(i.replace(\"\\n\",\"\"))\n",
        "pass1_out = p_list\n",
        "\n",
        "# reassign pass2_out\n",
        "tuple_list=[]\n",
        "a=open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori2_output.txt',\"r\").readlines()\n",
        "for i in a:\n",
        "    if i!=\"\":\n",
        "        temp=make_tuple(i)\n",
        "        if len(temp)<=4:\n",
        "            tuple_list.append(temp)\n",
        "pass2_out = tuple_list\n",
        "pass2_outFlat = np.array(pass2_out).flatten() #flat the list\n",
        "\n",
        "# reassign set up\n",
        "perc_min_supp = 0.02\n",
        "min_support = round(perc_min_supp*n_baskets) #filter the value of the\n",
        "print(\"Number of baskets considered in this project\",n_baskets)\n",
        "print(\"Min support considered is\",f\"{perc_min_supp:.0%}\", \"of the total number of baskets\")\n",
        "print(\"Total value of the min support\",min_support)\n",
        "\n",
        "# reassign based on results\n",
        "t_inter1 = 3003.8\n",
        "t_inter2 = 25835.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXRiJdFCXfha",
        "outputId": "1087cf36-e788-4eb0-d2dc-72f9a1c51667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of baskets considered in this project 14393620\n",
            "Min support considered is 2% of the total number of baskets\n",
            "Total value of the min support 287872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR5Ri7Jxg-9w"
      },
      "outputs": [],
      "source": [
        "# Check time\n",
        "startTime = time.time()\n",
        "\n",
        "# count triples\n",
        "sw_triples = count_freq_3(sw)\n",
        "#if sw_triples.isEmpty()==True: print(\"No frequent triples\")\n",
        "# create a list of frequent triples\n",
        "pass3_out = sw_triples.map(lambda x: x[0]).collect()\n",
        "#print(\"--> Frequent triples collected --> DONE\")\n",
        "\n",
        "# time check point\n",
        "intTime = time.time()\n",
        "t_inter3 =intTime-startTime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_Apriori = t_inter1+ t_inter2 + t_inter3\n",
        "\n",
        "# Print results and time of calculation\n",
        "print(\"\\n\")\n",
        "print(\"-> Intermediate time to calculate frequent triples: \", t_inter3)\n",
        "print(\"-> Total Duration: \", t_Apriori)\n",
        "print(\"\\n\")\n",
        "print(\"Number of frequent singletons\", len(pass1_out))\n",
        "print(\"Number of frequent pairs\", len(pass2_out))\n",
        "print(\"Number of frequent triples\", len(pass3_out))\n",
        "print(\"Total Duration: \", t_Apriori)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDOp412WNSI7",
        "outputId": "b62ebac8-15ab-4609-de0e-6334e66929f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "-> Intermediate time to calculate frequent triples:  13281.59319972992\n",
            "-> Total Duration:  42120.69319972992\n",
            "\n",
            "\n",
            "Number of frequent singletons 649\n",
            "Number of frequent pairs 180\n",
            "Number of frequent triples 0\n",
            "Total Duration:  42120.69319972992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save freq_triples into the output data folder\n",
        "with open('/content/drive/MyDrive/DSE_Colab_Output/algo_Apriori3_output.txt', 'w')  as file:\n",
        "    for i in pass3_out:\n",
        "        file.write(str(i)+\"\\n\")"
      ],
      "metadata": {
        "id": "3QUk-eR8vdRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wv6308Fdnmy"
      },
      "source": [
        "### PCY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x57o1TKce5Jy"
      },
      "source": [
        "Run full dataset analysis using PCY algorithm -> not feasible"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4WOtrYq2-m_F"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}